# Large Language Models

## LLMs development with MLOPs

MLOPs enables the tracking of model development with fast and easy deployment of the endpoints. 

A new branch of MLOPs is LLMOPs. Large Language Model Ops (LLMOps) encompasses the practices, techniques and tools used for the operational management of large language models in production environments.

![LLMOPs](https://cms.databricks.com/sites/default/files/inline-images/development-to-production-workflow-for-llms.png)

## Open Source LLM Models

| LLMs available for commercial use | Release Date | Checkpoints                                                                                                                                                          | Paper/Blog/Article  link                                                                                                                                                                                                                                                                                                           | Params (B)  | Context Length                                                                                                                                                                                                                                                         | Licence                                                                                                                                                                                                                                                       | Try it                                                                                                                |
| ------------------------------------------- | ------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- |
| LLaMA 2                                     | 7/1/2023     | [LLaMA 2 Weights](https://ai.meta.com/resources/models-and-libraries/llama-downloads/)                                                                               | [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://scontent-ham3-1.xx.fbcdn.net/v/t39.2365-6/10000000_662098952474184_2584067087619170692_n.pdf?_nc_cat=105&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=qhK-ahCbkBMAX94XV2X&_nc_ht=scontent-ham3-1.xx&oh=00_AfDB7dN8momft9nkv8X0gqrZdEnKltVjPOxhKBm0XLRinA&oe=64BE66FF) | 7 - 70      | [4096](https://scontent-ham3-1.xx.fbcdn.net/v/t39.2365-6/10000000_662098952474184_2584067087619170692_n.pdf?_nc_cat=105&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=qhK-ahCbkBMAX94XV2X&_nc_ht=scontent-ham3-1.xx&oh=00_AfDB7dN8momft9nkv8X0gqrZdEnKltVjPOxhKBm0XLRinA&oe=64BE66FF) | [](https://github.com/facebookresearch/llama/blob/main/LICENSE)[Custom](https://github.com/facebookresearch/llama/blob/main/LICENSE) | [HuggingChat](https://huggingface.co/blog/llama2#demo)                                                                |
| GPT-J-6B                                    | 2023/06      | GPT-J-6B, GPT4All-J                                                                                                                                                  | [GPT-J-6B: 6B JAX-Based Transformer](https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/)                                                                                                                                                                                                                         | 6           | [2048](https://github.com/kingoflolz/mesh-transformer-jax/#gpt-j-6b)                                                                                                                                                                                                   | Apache 2.0                                                                                                                                                                                                                                                    |                                                                                                                       |
| MPT-30B                                     | 2023/06      | MPT-30B, MPT-30B-instruct                                                                                                                                            | [MPT-30B: Raising the bar for open-source foundation models](https://www.mosaicml.com/blog/mpt-30b)                                                                                                                                                                                                                   | 30          | [8192](https://huggingface.co/mosaicml/mpt-30b/blob/main/config.json)                                                                                                                                                                                                  | Apache 2.0, CC BY-SA-3.0                                                                                                                                                                                                                                      | [MPT 30B inference code using CPU](https://github.com/abacaj/mpt-30B-inference)                                       |
| DLite                                       | 2023/05      | [dlite-v2-1_5b](https://huggingface.co/aisquared/dlite-v2-1_5b)                                                                                                      | [Announcing DLite V2: Lightweight, Open LLMs That Can Run Anywhere](https://medium.com/ai-squared/announcing-dlite-v2-lightweight-open-llms-that-can-run-anywhere-a852e5978c6e)                                                                                                                                       | 0.124 - 1.5 | [1024](https://huggingface.co/aisquared/dlite-v2-1_5b/blob/main/config.json)                                                                                                                                                                                           | Apache 2.0                                                                                                                                                                                                                                                    | [DLite-v2-1.5B](https://github.com/slai-labs/get-beam/tree/main/examples/dlite-v2)                                    |
| h2oGPT                                      | 2023/05      | [h2oGPT](https://github.com/h2oai/h2ogpt)                                                                                                                            | [Building the World’s Best Open-Source Large Language Model: H2O.ai’s Journey](https://h2o.ai/blog/building-the-worlds-best-open-source-large-language-model-h2o-ais-journey/)                                                                                                                                        | 12 - 20     | [256 - 2048](https://huggingface.co/h2oai)                                                                                                                                                                                                                             | Apache 2.0                                                                                                                                                                                                                                                    |                                                                                                                       |
| MPT-7B                                      | 2023/05      | MPT-7B, MPT-7B-Instruct                                                                                                                                              | [Introducing MPT-7B: A New Standard for Open-Source, Commercially Usable LLMs](https://www.mosaicml.com/blog/mpt-7b)                                                                                                                                                                                                  | 7           | [84k (ALiBi)](https://huggingface.co/mosaicml/mpt-7b#how-is-this-model-different)                                                                                                                                                                                      | Apache 2.0, CC BY-SA-3.0                                                                                                                                                                                                                                      |                                                                                                                       |
| RedPajama-INCITE                            | 2023/05      | [RedPajama-INCITE](https://huggingface.co/togethercomputer)                                                                                                          | [Releasing 3B and 7B RedPajama-INCITE family of models including base, instruction-tuned & chat models](https://www.together.xyz/blog/redpajama-models-v1)                                                                                                                                                            | 3 - 7       | [2048](https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-7B-v0.1/blob/157bf3174feebb67f37e131ea68f84dee007c687/config.json#L13)                                                                                                                        | Apache 2.0                                                                                                                                                                                                                                                    | [RedPajama-INCITE-Instruct-3B-v1](https://github.com/slai-labs/get-beam/tree/main/examples/redpajama-incite-instruct) |
| OpenLLaMA                                   | 2023/05      | open_llama_3b, open_llama_7b, open_llama_13b                                                                                                                         | [OpenLLaMA: An Open Reproduction of LLaMA](https://github.com/openlm-research/open_llama)                                                                                                                                                                                                                             | 3, 7        | [2048](https://huggingface.co/h2oai)                                                                                                                                                                                                                                   | Apache 2.0                                                                                                                                                                                                                                                    | [OpenLLaMA-7B-Preview_200bt](https://github.com/slai-labs/get-beam/tree/main/examples/openllama)                      |
| Falcon                                      | 2023/05      | Falcon-40B, Falcon-7B                                                                                                                                                | [The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only](https://arxiv.org/abs/2306.01116)                                                                                                                                                                             | 7, 40       | [2048](https://huggingface.co/tiiuae/falcon-7b/blob/main/config.json)                                                                                                                                                                                                  | Apache 2.0                                                                                                                                                                                                                                                    |                                                                                                                       |
| Pythia                                      | 2023/04      | [pythia 70M - 12B](https://github.com/EleutherAI/pythia)                                                                                                             | [Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling](https://arxiv.org/abs/2304.01373)                                                                                                                                                                                                   | 0.07 - 12   | [2048](https://arxiv.org/pdf/2304.01373.pdf)                                                                                                                                                                                                                           | Apache 2.0                                                                                                                                                                                                                                                    |                                                                                                                       |
| Dolly                                       | 2023/04      | [dolly-v2-12b](https://huggingface.co/databricks/dolly-v2-12b)                                                                                                       | [Free Dolly: Introducing the World's First Truly Open Instruction-Tuned LLM](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm)                                                                                                                                   | 3, 7, 12    | [2048](https://github.com/databrickslabs/dolly#dolly)                                                                                                                                                                                                                  | MIT                                                                                                                                                                                                                                                           |                                                                                                                       |
| StableLM-Alpha                              | 2023/04      | [StableLM-Alpha](https://github.com/Stability-AI/StableLM#stablelm-alpha)                                                                                            | [Stability AI Launches the First of its StableLM Suite of Language Models](https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models)                                                                                                                                        | 3 - 65      | [4096](https://github.com/Stability-AI/StableLM#stablelm-alpha)                                                                                                                                                                                                        | CC BY-SA-4.0                                                                                                                                                                                                                                                  |                                                                                                                       |
| FastChat-T5                                 | 2023/04      | [fastchat-t5-3b-v1.0](https://huggingface.co/lmsys/fastchat-t5-3b-v1.0)                                                                                              | [We are excited to release FastChat-T5: our compact and commercial-friendly chatbot!](https://twitter.com/lmsysorg/status/1652037026705985537?s=20)                                                                                                                                                                   | 3           | [512](https://huggingface.co/lmsys/fastchat-t5-3b-v1.0/blob/main/config.json)                                                                                                                                                                                          | Apache 2.0                                                                                                                                                                                                                                                    |                                                                                                                       |
| Cerebras-GPT                                | 2023/03      | [Cerebras-GPT](https://huggingface.co/cerebras)                                                                                                                      | Cerebras-GPT: A Family of Open, Compute-efficient, Large Language Models (Paper)                                                                                                                                                                                                                                      | 0.111 - 13  | [2048](https://huggingface.co/cerebras/Cerebras-GPT-13B#model-details)                                                                                                                                                                                                 | Apache 2.0                                                                                                                                                                                                                                                    | [Cerebras-GPT-1.3B](https://github.com/slai-labs/get-beam/tree/main/examples/cerebras-gpt)                            |
| Open Assistant (Pythia family)              | 2023/03      | OA-Pythia-12B-SFT-8, OA-Pythia-12B-SFT-4, OA-Pythia-12B-SFT-1                                                                                                        | [Democratizing Large Language Model Alignment](https://arxiv.org/abs/2304.07327)                                                                                                                                                                                                                                      | 12          | [2048](https://huggingface.co/OpenAssistant/pythia-12b-sft-v8-7k-steps/blob/main/config.json)                                                                                                                                                                          | Apache 2.0                                                                                                                                                                                                                                                    | [Pythia-2.8B](https://github.com/slai-labs/get-beam/tree/main/examples/pythia)                                        |
| Bloom                                       | 2022/11      | [Bloom](https://huggingface.co/bigscience/bloom)                                                                                                                     | [BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://arxiv.org/abs/2211.05100)                                                                                                                                                                                                                   | 176         | [2048](https://huggingface.co/bigscience/bloom)                                                                                                                                                                                                                        | [OpenRAIL-M v1](https://huggingface.co/spaces/bigcode/bigcode-model-license-agreement)                                                                                                                                                                        |                                                                                                                       |
| UL2                                         | 2022/10      | UL2 & Flan-UL2, Flan-UL2 (HF)                                                                                                                                        | [UL2 20B: An Open Source Unified Language Learner](https://ai.googleblog.com/2022/10/ul2-20b-open-source-unified-language.html)                                                                                                                                                                                       | 20          | [512, 2048](https://huggingface.co/google/flan-ul2#tldr)                                                                                                                                                                                                               | Apache 2.0                                                                                                                                                                                                                                                    |                                                                                                                       |
| GPT-NeoX-20B                                | 2022/04      | [GPT-NEOX-20B](https://huggingface.co/EleutherAI/gpt-neox-20b)                                                                                                       | [GPT-NeoX-20B: An Open-Source Autoregressive Language Model](https://arxiv.org/abs/2204.06745)                                                                                                                                                                                                                        | 20          | [2048](https://huggingface.co/EleutherAI/gpt-neox-20b)                                                                                                                                                                                                                 | Apache 2.0                                                                                                                                                                                                                                                    |                                                                                                                       |
| RWKV                                        | 2021/08      | [RWKV, ChatRWKV](https://github.com/BlinkDL/RWKV-LM#rwkv-parallelizable-rnn-with-transformer-level-llm-performance-pronounced-as-rwakuv-from-4-major-params-r-w-k-v) | [The RWKV Language Model (and my LM tricks)](https://github.com/BlinkDL/RWKV-LM)                                                                                                                                                                                                                                      | 0.1 - 14    | [infinity (RNN)](https://github.com/BlinkDL/RWKV-LM#rwkv-parallelizable-rnn-with-transformer-level-llm-performance-pronounced-as-rwakuv-from-4-major-params-r-w-k-v)                                                                                                   | Apache 2.0                                                                                                                                                                                                                                                    |                                                                                                                       |
| T5                                          | 2019/10      | T5 & Flan-T5, Flan-T5-xxl (HF)                                                                                                                                       | [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://github.com/google-research/text-to-text-transfer-transformer#released-model-checkpoints)                                                                                                                                  | 0.06 - 11   | [512](https://discuss.huggingface.co/t/does-t5-truncate-input-longer-than-512-internally/3602)                                                                                                                                                                         | Apache 2.0                                                                                                                                                                                                                                                    | [T5-Large](https://github.com/slai-labs/get-beam/tree/main/examples/t5)                                               |


## Different managed services for deploying AI models

| Vendor      | Service                             | Documentation                                                                                                                                                                                           | Serverless option | GPU Suuports                                  | Instance               | GPU memory | $Cost/hr (On-demand) | $cost/hr (Spot) |                                                                                                                                                                                                                                                                                                               |
| ----------- | ----------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------- | --------------------------------------------- | ---------------------- | ---------- | -------------------- | --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
|             |                                     |                                                                                                                                                                                                         |                   |                                               |                        |            |                      |                 |                                                                                                                                                                                                                                                                                                               |
| Google      | Vertex AI<br>AI Platform Prediction | [https://cloud.google.com/ai-platform/prediction/docs/deploying-models](https://cloud.google.com/ai-platform/prediction/docs/deploying-models)                                                          | Yes               | A-100                                         |                        | 40GB       | 3.67                 |                 | [https://cloud.google.com/compute/gpus-pricing](https://cloud.google.com/compute/gpus-pricing)                                                                                                                                                                                                                |
| V-100       |                                     | 16GB                                                                                                                                                                                                    | 2.48              |                                               |                        |
| P-100       |                                     | 16GB                                                                                                                                                                                                    | 1.46              |                                               |                        |
|             |                                     |
| AWS         | Sagemaker                           | [https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html)                                                                  | Yes               | A-100                                         | p4de.24xlarge<br>8 GPU | 80GB       | 40.97                | \-              |                                                                                                                                                                                                                                                                                                               |
|             |                                     |                                                                                                                                                                                                         |                   | A-100                                         | p4d.24xlarge<br>8 GPU  | 40GB       | 32.77                | 9.84            |                                                                                                                                                                                                                                                                                                               |
|             |                                     |                                                                                                                                                                                                         |                   | V-100                                         | p3.2xlarge<br>1 GPU    | 16GB       | 3.06                 | 0.9             |                                                                                                                                                                                                                                                                                                               |
|             |                                     |                                                                                                                                                                                                         |                   |                                               |                        |            |                      |                 |                                                                                                                                                                                                                                                                                                               |
|             |                                     |                                                                                                                                                                                                         |                   | A-10                                          | g5.4xlarge<br>1 GPU    | 24GB       | 1.42                 | 0.7             |                                                                                                                                                                                                                                                                                                               |
|             |                                     | Foundation Models<br>[https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-choose.html](https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-choose.html) |                   |                                               |                        |            |                      |                 | SDK Example<br>[https://github.com/aws-samples/sagemaker-foundation-model-examples/blob/main/JumpStart-Models/huggingface-text-generation-bloom-1b1-SDK.ipynb](https://github.com/aws-samples/sagemaker-foundation-model-examples/blob/main/JumpStart-Models/huggingface-text-generation-bloom-1b1-SDK.ipynb) |
|             |                                     |
| Azure       | AzureML                             | [https://learn.microsoft.com/en-us/azure/machine-learning/concept-endpoints?view=azureml-api-2](https://learn.microsoft.com/en-us/azure/machine-learning/concept-endpoints?view=azureml-api-2)          | Yes               | A-100                                         |                        | 80GB       | 3.67                 |                 |                                                                                                                                                                                                                                                                                                               |
|             |                                     |                                                                                                                                                                                                         |                   | V-100                                         |                        | 16GB       | 3.06                 |                 |                                                                                                                                                                                                                                                                                                               |
|             |                                     |                                                                                                                                                                                                         |                   | P-100                                         |                        | 16Gb       | 2.07                 |                 |                                                                                                                                                                                                                                                                                                               |
|             |                                     |
| Lambda      | Lambda                              |                                                                                                                                                                                                         |                   | A-100                                         |                        | 80GB       | 1.5                  |                 | [https://lambdalabs.com/service/gpu-cloud/pricing](https://lambdalabs.com/service/gpu-cloud/pricing)                                                                                                                                                                                                          |
|             |                                     |                                                                                                                                                                                                         |                   | A-100                                         |                        | 40GB       | 1.1                  |                 |                                                                                                                                                                                                                                                                                                               |
|             |                                     |                                                                                                                                                                                                         |                   | V-100                                         |                        | 16GB       | 4.4                  |                 |                                                                                                                                                                                                                                                                                                               |
|             |                                     |                                                                                                                                                                                                         |                   |                                               |                        |            |                      |                 | [https://datacrunch.io/products](https://datacrunch.io/products)                                                                                                                                                                                                                                              |
| DataCrunch  |                                     |                                                                                                                                                                                                         | Yes               | A-100                                         |                        | 40         | 1.95                 |                 |                                                                                                                                                                                                                                                                                                               |
|             |                                     |                                                                                                                                                                                                         |                   | V-100                                         |                        | 16         | 0.89                 |                 |                                                                                                                                                                                                                                                                                                               |
|             |                                     |                                                                                                                                                                                                         |                   |                                               |                        |            |                      |                 |                                                                                                                                                                                                                                                                                                               |
|             |                                     |                                                                                                                                                                                                         |                   |                                               |                        |            |                      |                 |                                                                                                                                                                                                                                                                                                               |
|             |                                     |                                                                                                                                                                                                         |                   |                                               |                        |            |                      |                 |                                                                                                                                                                                                                                                                                                               |
| Huggingface |                                     | [https://huggingface.co/inference-endpoints](https://huggingface.co/inference-endpoints)                                                                                                                | Yes               | Uses AWS instacens in backend. Similar to aws |                        |            |                      |                 | [https://huggingface.co/pricing#endpoints](https://huggingface.co/pricing#endpoints)                                                                                                                                                                                                                          |

## Deployment on AWS Sagemaker


### Sagemaker instances for Llama-2

Weekly cost is calculated considering 2 hrs per day and 5 workdays total 10 week hours (Only Deployment estimate)

| Model Name       | Model ID                          | Max Total Tokens | Default Instance Type | $Pricing/hr (Ondemand) | $Pricing/Week (Ondemand) | $Pricing/hr (spot) | $Pricing/Week (spot) | vCPUs | Instance Memory (GiB) | GPU Model | GPUs | Total GPU Memory (GiB) | Memory per GPU (GB) |
| ---------------- | --------------------------------- | ---------------- | --------------------- | ---------------------- | ------------------------ | ------------------ | -------------------- | ----- | --------------------- | --------- | ---- | ---------------------- | ------------------- |
| Llama-2-7b       | meta-textgeneration-llama-2-7b    | 4096             | ml.g5.2xlarge         | 1.212                  | 12.12                    | 0.3636             | 3.636                | 8     | 32                    | A10G      | 1    | 24                     | 24                  |
| Llama-2-7b-chat  | meta-textgeneration-llama-2-7b-f  | 4096             | ml.g5.2xlarge         | 1.212                  | 12.12                    | 0.3636             | 3.636                | 8     | 32                    | A10G      | 1    | 24                     | 24                  |
| Llama-2-13b      | meta-textgeneration-llama-2-13b   | 4096             | ml.g5.12xlarge        | 5.672                  | 56.72                    | 1.943              | 19.43                | 48    | 192                   | A10G      | 4    | 96                     | 24                  |
| Llama-2-13b-chat | meta-textgeneration-llama-2-13b-f | 4096             | ml.g5.12xlarge        | 5.672                  | 56.72                    | 1.943              | 19.43                | 48    | 192                   | A10G      | 4    | 96                     | 24                  |
| Llama-2-70b      | meta-textgeneration-llama-2-70b   | 4096             | ml.g5.48xlarge        | 16.288                 | 162.88                   | 7.638              | 76.38                | 192   | 768                   | A10G      | 8    | 192                    | 24                  |
| Llama-2-70b-chat | meta-textgeneration-llama-2-70b-f | 4096             | ml.g5.48xlarge        | 16.288                 | 162.88                   | 7.638              | 76.38                | 192   | 768                   | A10G      | 8    | 192                    | 24                  |


### Creating inference on AWS Sagemaker

**Creating the inference using Sagemaker Console**

![Drag Racing](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/17/ML-15102-image001.jpg)

![Drag Racing](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/17/ML-15102-image003.jpg)


**Creating the inference using Python SDK**

``` { .yaml .annotate }
from sagemaker.jumpstart.model import JumpStartModel
my_model = JumpStartModel(model_id = "meta-textgeneration-llama-2-70b-f")
predictor = my_model.deploy()
```

**Sending Requests**
``` { .yaml .annotate }
payload = {
    “inputs”:  
      [
        [
         {"role": "system", "content": "Always answer with Haiku"},
         {"role": "user", "content": "I am going to Paris, what should I see?"},
        ]   
      ],
   "parameters":{"max_new_tokens":256, "top_p":0.9, "temperature":0.6}
}
predictor.predict(payload, custom_attributes="accept_eula=true")
```

**Finetuning Llama-2 using Sagemaker Console**

We can use both domain adaptation and instruction tuning datasets to perform fine-tuning of the base model. Fine-tuning scripts are based on the scripts provided by this [repo](https://github.com/facebookresearch/llama-recipes/blob/main/LICENSE). They utilize Fully Sharded Data Parallel (FSDP) library as well as Low Rank Adaptation (LoRA) method fine-tuning the models efficiently. You can tune any of the 14 hyper-parameters to adapt fine-tuning for your application. To learn more, please see the [Fine-tune LLaMA 2 models on SageMaker JumpStart](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/jumpstart-foundation-models/llama-2-finetuning.ipynb).

![Finetuning](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/11/llama-fine-tuning.jpg)

<!-- ## Deployment on Hugging Face  -->

## LLM Security

Secure LLM layer for LLM security

1. Promt injection security.  
        a. Detecting prompt injection and saving from data leak. 
2. LLM input/output moderation.  
        a. Making the bot stick to a specific topic of conversation.  
        b. Moderating a bot's response.  
        c. Ensuring factual answers.
3. LLM output control to save excess information leak.  
       a. Controlling the output with user role scopes.   
       b. Eg. An employee cannot ask the financial summary.  
